from datetime import dateimport datetimeimport globimport osimport reimport feedparserimport sslimport timeimport subprocessimport textwrapdirpath = os.path.dirname(os.path.abspath(__file__))datenow=str(datetime.datetime.now())[:16]timenow = str(time.time())today = date.today()print timenowprint todayprint datenownewspath = dirpath+"\\output\\"+timenow+".txt"imgpath = dirpath+"\\output\\"+timenow+".png"mp3path = dirpath+"\\output\\"+timenow+".mp3"mp4path = dirpath+"\\output\\"+timenow+".mov"voice = "\"IVONA 2 Salli\""rss = "https://news.google.com/news?cf=all&hl=en&pz=1&ned=us&output=rss"if hasattr(ssl, '_create_unverified_context'):    ssl._create_default_https_context = ssl._create_unverified_contextfeed = feedparser.parse(rss) #<<WORKS!!#print[field for field in feed]#import pprint#pprint.pprint(entry for entry in feed['entries'])titles = [entry.title for entry in feed['entries']]news = ""news_balabolka = ""noduplicates = 0for title in titles:    #title = re.sub("(.{10})", '\\1\n', title, 0, re.DOTALL)    #print title    title = title.encode("utf-8")    title_nosource=re.sub("\s\-\s.*","",title)    ###title_nosource = r"\n".join(textwrap.wrap(title_nosource, 85))    title_source=re.sub(".*\s\-\s","",title)    isduplicate = 0    filenames = glob.glob("output/*.txt")    print filenames    for fname in filenames:        with open(fname) as infile:            for line in infile:                if title_nosource[:85] in line[:85]:                    isduplicate = 1                        if isduplicate == 0:        print "no duplicate"        noduplicates =+ 1        news = news+(title_source.upper()+": "+r"\n".join(textwrap.wrap(title_nosource, 85))+r"\n"r"\n")        #news_balabolka = news_balabolka+(title_source+" reports: "+title_nosource+". ")        news_balabolka = news_balabolka+(title_nosource+". ")        news_balabolka = news_balabolka.replace("|",".")    else:        print "duplicate"#print newsif noduplicates > 0:    #pointsize = 15000/len(news)    pointsize = 28    print pointsize    f = open(newspath, 'wb+')    f.write(news)    f.close()    #subprocess.check_output(["magick", "-background", "transparent", "-gravity","center", "-fill","white", "-font","Verdana", "-size","1820x980", "-density", "120", "-strokewidth", "10", "-stroke", "black", "label:"+news, "-bordercolor", "transparent", "-border", "50x50", imgpath],shell=True)        subprocess.check_output(["magick","-pointsize", str(pointsize), "-fill", "white", "-background", "transparent", "-font", "Arial", "-size","1820x980", "-strokewidth", "1", "-stroke", "white", "label: News for "+datenow+r"\n"r"\n"+news,"-bordercolor", "transparent", "-border", "50x50", imgpath],shell=True)    subprocess.call(["magick", "composite", imgpath, "background.jpg", imgpath])    f = open('test.cmd', 'w+')    f.write(""+dirpath+"\\balcon.exe -s 0 -sb 500 -se 500 -n "+voice+" -t \""+news_balabolka+"\" -w "+mp3path+"")    #f.write(""+dirpath+"\\balcon.exe -n "+voice+" -fr 48 -t "+line+" -o --raw | "+dirpath+"\\lame.exe -r -s 48 -m m -h - "+dirpath+"\\mp3path")    f.close()    os.system("runas /savecred /profile /user:Honza "+dirpath+"\\test.cmd")    time.sleep(10)    #os.system("lame.exe -V2 wavpath mp3path")    #time.sleep(10)    subprocess.check_output(["ffmpeg.exe", "-y","-loop", "1", "-i", imgpath, "-i", mp3path, "-c:v", "libx264", "-c:a", "copy", "-vf", "scale=trunc(iw/2)*2:trunc(ih/2)*2", "-shortest", mp4path], shell=True)    subprocess.call(dirpath+"\\output\\upload.py", shell=True)os.remove(mp3path)os.remove(imgpath)print "Media processing done."#!/usr/bin/python# -*- coding: cp1250 -*-import datetimeimport httplibimport httplib2import osimport randomimport sysimport timefrom apiclient.discovery import buildfrom apiclient.errors import HttpErrorfrom apiclient.http import MediaFileUploadfrom oauth2client.client import flow_from_clientsecretsfrom oauth2client.file import Storagefrom oauth2client.tools import argparser, run_flowlimit = 2 #SET NUMBER OF FILES TO UPLOAD#datenow=str(datetime.datetime.now())[:16]files = []files.append(mp4path)# Explicitly tell the underlying HTTP transport library not to retry, since# we are handling retry logic ourselves.httplib2.RETRIES = 1# Maximum number of times to retry before giving up.MAX_RETRIES = 10# Always retry when these exceptions are raised.RETRIABLE_EXCEPTIONS = (httplib2.HttpLib2Error, IOError, httplib.NotConnected,  httplib.IncompleteRead, httplib.ImproperConnectionState,  httplib.CannotSendRequest, httplib.CannotSendHeader,  httplib.ResponseNotReady, httplib.BadStatusLine)# Always retry when an apiclient.errors.HttpError with one of these status# codes is raised.RETRIABLE_STATUS_CODES = [500, 502, 503, 504]# The CLIENT_SECRETS_FILE variable specifies the name of a file that contains# the OAuth 2.0 information for this application, including its client_id and# client_secret. You can acquire an OAuth 2.0 client ID and client secret from# the Google Developers Console at# https://console.developers.google.com/.# Please ensure that you have enabled the YouTube Data API for your project.# For more information about using OAuth2 to access the YouTube Data API, see:#   https://developers.google.com/youtube/v3/guides/authentication# For more information about the client_secrets.json file format, see:#   https://developers.google.com/api-client-library/python/guide/aaa_client_secretsCLIENT_SECRETS_FILE = "client_secrets.json"# This OAuth 2.0 access scope allows an application to upload files to the# authenticated user's YouTube channel, but doesn't allow other types of access.YOUTUBE_UPLOAD_SCOPE = "https://www.googleapis.com/auth/youtube.upload"YOUTUBE_API_SERVICE_NAME = "youtube"YOUTUBE_API_VERSION = "v3"# This variable defines a message to display if the CLIENT_SECRETS_FILE is# missing.MISSING_CLIENT_SECRETS_MESSAGE = """WARNING: Please configure OAuth 2.0To make this sample run you will need to populate the client_secrets.json filefound at:   %swith information from the Developers Consolehttps://console.developers.google.com/For more information about the client_secrets.json file format, please visit:https://developers.google.com/api-client-library/python/guide/aaa_client_secrets""" % os.path.abspath(os.path.join(os.path.dirname(__file__),                                   CLIENT_SECRETS_FILE))VALID_PRIVACY_STATUSES = ("public", "private", "unlisted")def get_authenticated_service(args):  flow = flow_from_clientsecrets(CLIENT_SECRETS_FILE,    scope=YOUTUBE_UPLOAD_SCOPE,    message=MISSING_CLIENT_SECRETS_MESSAGE)  storage = Storage("%s-oauth2.json" % sys.argv[0])  credentials = storage.get()  if credentials is None or credentials.invalid:    credentials = run_flow(flow, storage, args)  return build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION,    http=credentials.authorize(httplib2.Http()))def initialize_upload(youtube, options):  tags = None  if options.keywords:    tags = options.keywords.split(",")  body=dict(    snippet=dict(      title=options.title,      description=options.description,      tags=tags,      categoryId=options.category    ),    status=dict(      privacyStatus=options.privacyStatus    )  )  # Call the API's videos.insert method to create and upload the video.  insert_request = youtube.videos().insert(    part=",".join(body.keys()),    body=body,    # The chunksize parameter specifies the size of each chunk of data, in    # bytes, that will be uploaded at a time. Set a higher value for    # reliable connections as fewer chunks lead to faster uploads. Set a lower    # value for better recovery on less reliable connections.    #    # Setting "chunksize" equal to -1 in the code below means that the entire    # file will be uploaded in a single HTTP request. (If the upload fails,    # it will still be retried where it left off.) This is usually a best    # practice, but if you're using Python older than 2.6 or if you're    # running on App Engine, you should set the chunksize to something like    # 1024 * 1024 (1 megabyte).    media_body=MediaFileUpload(options.file, chunksize=-1, resumable=True)  )  resumable_upload(insert_request)# This method implements an exponential backoff strategy to resume a# failed upload.def resumable_upload(insert_request):  response = None  error = None  retry = 0  while response is None:    try:      print "Uploading file..."      status, response = insert_request.next_chunk()      if 'id' in response:        print "Video id '%s' was successfully uploaded." % response['id']      else:        exit("The upload failed with an unexpected response: %s" % response)    except HttpError, e:      if e.resp.status in RETRIABLE_STATUS_CODES:        error = "A retriable HTTP error %d occurred:\n%s" % (e.resp.status,                                                             e.content)      else:        raise    except RETRIABLE_EXCEPTIONS, e:      error = "A retriable error occurred: %s" % e    if error is not None:      print error      retry += 1      if retry > MAX_RETRIES:        exit("No longer attempting to retry.")      max_sleep = 2 ** retry      sleep_seconds = random.random() * max_sleep      print "Sleeping %f seconds and then retrying..." % sleep_seconds      time.sleep(sleep_seconds)if __name__ == '__main__':  argparser.add_argument("--description", help="Video description", default='')  argparser.add_argument("--category", default="25", help="Numeric video category. " + "See https://developers.google.com/youtube/v3/docs/videoCategories/list")  argparser.add_argument("--keywords", help="Video keywords, comma separated", default="world news, updates, washington post, new york times, la times, cnn, politico, bbc news, nbc")  args = argparser.parse_args()  args.privacyStatus = "public"  args.file = files  i = 1  print "Limit set to "+str(limit)+" files."  if files == []:      print "No files to process in this folder."  for x in args.file:      try:          if not i > limit:               args.file = x                        print "File "+str(i)              print x              args.title = x[:-4]                       lic = "Creative Commons"              with open(args.title+".txt", 'r') as myfile:                  extra=myfile.read()                  extra=extra.replace(r"\n","\n")              source = "https://news.google.com/?output=rss" #SET ATTRIBUTION WEBSITE HERE              args.title = args.title[:100] #shorten              args.title = "Dolores News for "+datenow              args.description = (extra+'\n\nSource: '+source+'\nLicense: '+lic)              args.description = args.description[:5000]              #args.description = unicode(args.description, errors='ignore') #DEAL WITH DIFFICULTIES              youtube = get_authenticated_service(args)              try:                  initialize_upload(youtube, args)                  if not os.path.exists('output/uploaded'):                      os.makedirs('output/uploaded')                  os.rename(x, "output/uploaded/"+x)                  i=i+1              except HttpError, e:                  print "An HTTP error %d occurred:\n%s" % (e.resp.status, e.content)                  pass      except:          passos.rename(mp4path,dirpath+"\\output\\uploaded\\"+timenow+".mov")